{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import torch \n",
    "from torchvision import transforms, models \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niteeqsheik/anaconda3/envs/WebDB_Project/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/niteeqsheik/anaconda3/envs/WebDB_Project/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet_model = models.resnet50(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "8677\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.Caltech101('/Users/niteeqsheik/Desktop/CSE515-Project(Git)',download=True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "batch_size=4,\n",
    "shuffle=True,\n",
    "num_workers=8)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is ID:8000\n",
      "label:92\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=60x60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_ID =8000\n",
    "img, label = dataset[image_ID]\n",
    "print(f'This is ID:{image_ID}')\n",
    "print(f'label:{label}')\n",
    "newsize = (60, 60)\n",
    "img = img.resize(newsize)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_caltech_101 = np.array([dataset[i][1] for i in range(len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_caltech_101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8677 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8677/8677 [05:59<00:00, 24.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize an empty list to store color moments\n",
    "color_moments_list = []\n",
    "\n",
    "# Initialize an empty list to store img_arrays (if needed)\n",
    "all_img_arrays = []\n",
    "\n",
    "# Loop through the dataset\n",
    "for image_ID in tqdm(range(len(dataset))):\n",
    "    img, label = dataset[image_ID]\n",
    "    \n",
    "    # Step 1: Resize the image to 300x100\n",
    "    new_size = (300, 100)\n",
    "    img_resized = img.resize(new_size)\n",
    "    \n",
    "    # Convert the PIL Image to a NumPy array\n",
    "    img_array = np.array(img_resized)\n",
    "    \n",
    "    #grayscale image check \n",
    "    is_gray = len(img_array.shape) == 2\n",
    "    \n",
    "    # Append the img_array to the list (if you need to keep all arrays)\n",
    "    all_img_arrays.append(img_array)\n",
    "\n",
    "    # Step 2: Partition the image into a 10x10 grid\n",
    "    for i in range(0, 300, 30):\n",
    "        for j in range(0, 100, 10):\n",
    "            grid_cell = img_array[j:j+10, i:i+30]\n",
    "            \n",
    "            # Step 3: Calculate the color moments for each grid cell\n",
    "            color_moments_dict = {}\n",
    "            for color_channel, color_name in enumerate(['Gray'] if is_gray else ['Red', 'Green', 'Blue']):\n",
    "                channel_data = grid_cell if is_gray else grid_cell[:, :, color_channel]\n",
    "\n",
    "                # Calculate mean, standard deviation, and skewness\n",
    "                channel_mean = np.mean(channel_data)\n",
    "                channel_std = np.std(channel_data)\n",
    "                if np.all(channel_data == channel_data[0]):\n",
    "                    channel_skewness = 0\n",
    "                else :\n",
    "                    channel_skewness = skew(channel_data.reshape(-1))\n",
    "                \n",
    "                # Store the color moments in the dictionary\n",
    "                color_moments_dict[f\"{color_name}_Mean\"] = channel_mean\n",
    "                color_moments_dict[f\"{color_name}_Std\"] = channel_std\n",
    "                color_moments_dict[f\"{color_name}_Skewness\"] = channel_skewness\n",
    "            \n",
    "            # Include the ImageID\n",
    "            color_moments_dict[\"ImageID\"] = image_ID\n",
    "            \n",
    "            # Append the color moments to the list\n",
    "            color_moments_list.append(color_moments_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use hog_features_dict as the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting HOG features: 100%|██████████| 8677/8677 [00:57<00:00, 150.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you've already loaded the dataset like this:\n",
    "# dataset = datasets.Caltech101('/path/to/dataset', download=True)\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    # Convert PIL Image to NumPy array\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Check if the image is grayscale\n",
    "    if len(image_np.shape) == 2:\n",
    "        gray_image = image_np\n",
    "    else:\n",
    "        gray_image = rgb2gray(image_np)\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_image = resize(gray_image, (300, 100))\n",
    "    \n",
    "    # Compute the HOG features\n",
    "    features, hog_image = hog(resized_image, orientations=9, pixels_per_cell=(30, 10),\n",
    "                              cells_per_block=(1, 1), visualize=True)\n",
    "    \n",
    "    return features, hog_image\n",
    "\n",
    "# Initialize empty dictionaries to store features and labels\n",
    "hog_features_dict = {}\n",
    "hog_images_dict = {}\n",
    "labels_dict = {}\n",
    "\n",
    "# Loop over the dataset with progress bar\n",
    "for i in tqdm(range(len(dataset)), desc=\"Extracting HOG features\"):\n",
    "    image, label = dataset[i]\n",
    "    features, hog_image = extract_hog_features(image)\n",
    "    hog_features_dict[i] = features\n",
    "    hog_images_dict[i] = hog_image\n",
    "    labels_dict[i] = label\n",
    "\n",
    "# Now:\n",
    "# hog_features_dict contains the 900-dimensional feature descriptor for each image, indexed by dataset index\n",
    "# hog_images_dict contains the visual representation of the HOG features for each image, indexed by dataset index\n",
    "# labels_dict contains the label for each image, indexed by dataset index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900,)\n"
     ]
    }
   ],
   "source": [
    "print(hog_features_dict[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hog_features_df = pd.DataFrame.from_dict(hog_features_dict, orient=\"index\")\n",
    "\n",
    "hog_features_df[\"ImageID\"] = hog_features_df.index\n",
    "\n",
    "csv_file_name = \"hog_features.csv\"\n",
    "hog_features_df.to_csv(csv_file_name,index=False)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867700\n"
     ]
    }
   ],
   "source": [
    "print(len(color_moments_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet computations \n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize([0.53994344, 0.52009986, 0.49254049], \n",
    "                         [0.31415099, 0.30712622, 0.31878401]),  # Normalize the images\n",
    "])\n",
    "\n",
    "def resnet_computations(hook_layer, dataset):\n",
    "    \n",
    "    # List to store the output tensors for each image along with their ImageID\n",
    "    outputs_with_ids = []\n",
    "    skipped_images = []\n",
    "    \n",
    "    # List to temporarily capture the output tensor from the hook\n",
    "    captured_output = [None]\n",
    "\n",
    "    # Hook function to capture the output tensor of a specified layer\n",
    "    def capture_output(module, input, output):\n",
    "        captured_output[0] = output\n",
    "\n",
    "    # Register the hook function to the specified layer\n",
    "    if hook_layer == 'avgpool':\n",
    "        hook = resnet_model.avgpool.register_forward_hook(capture_output)\n",
    "    elif hook_layer == 'layer3':\n",
    "        hook = resnet_model.layer3.register_forward_hook(capture_output)\n",
    "    elif hook_layer == 'fc':   \n",
    "        hook = resnet_model.fc.register_forward_hook(capture_output)\n",
    "\n",
    "    # Loop through the dataset\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        try:\n",
    "            img, label = dataset[i]\n",
    "            #skipping grayscale images \n",
    "            if img.mode == 'L' or img.mode == '1':\n",
    "                img = img.convert(\"RGB\")\n",
    "\n",
    "            # Apply transformations and prepare image batch\n",
    "            img_tensor = transform(img)\n",
    "            img_batch = img_tensor.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "            # Forward pass (disable gradient computation to save memory)\n",
    "            with torch.no_grad():\n",
    "                resnet_model(img_batch)\n",
    "            \n",
    "            # Retrieve the captured output tensor\n",
    "            resnet_output = captured_output[0]\n",
    "            if resnet_output is None:\n",
    "                print(\"Warning: Hook Not Triggered\")\n",
    "                skipped_images.append(i)\n",
    "                continue\n",
    "\n",
    "            # Process the output tensor depending on the specified layer and store it in a dictionary\n",
    "            output_dict = {\"ImageID\": i}\n",
    "            if hook_layer == 'avgpool':\n",
    "                avgpool_output = resnet_output.flatten().cpu().numpy()\n",
    "                averaged_values = [(avgpool_output[i] + avgpool_output[i+1]) / 2.0 for i in range(0, len(avgpool_output), 2)]\n",
    "                output_dict[\"Output\"] = np.array(averaged_values)\n",
    "            elif hook_layer == 'layer3':\n",
    "                avg_vector = resnet_output.mean(dim=[2, 3]).cpu().numpy().squeeze()\n",
    "                output_dict[\"Output\"] = avg_vector\n",
    "            elif hook_layer == 'fc':\n",
    "                output_dict[\"Output\"] = resnet_output.cpu().numpy().squeeze()\n",
    "            \n",
    "            # Append the dictionary to the list\n",
    "            outputs_with_ids.append(output_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing ImageID {i}: {e}\")\n",
    "            skipped_images.append(i)\n",
    "    # Remove the hook to free resources\n",
    "    hook.remove()\n",
    "    \n",
    "    return outputs_with_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8677/8677 [05:45<00:00, 25.15it/s]\n"
     ]
    }
   ],
   "source": [
    "output_avgpool_with_ids = resnet_computations('avgpool',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n"
     ]
    }
   ],
   "source": [
    "print(len(output_avgpool_with_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8677/8677 [06:56<00:00, 20.81it/s]\n"
     ]
    }
   ],
   "source": [
    "output_layers3_with_ids = resnet_computations('layer3',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n"
     ]
    }
   ],
   "source": [
    "print(len(output_layers3_with_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8677/8677 [06:58<00:00, 20.73it/s]\n"
     ]
    }
   ],
   "source": [
    "output_fc_with_ids = resnet_computations('fc',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n"
     ]
    }
   ],
   "source": [
    "print(len(output_fc_with_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# df_color_moments = pd.read_csv(\"color_moments_with_imageID.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_color_moments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_columns = df_color_moments.columns[1:-1]\n",
    "# data_color_moments = df_color_moments[feature_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_color_moments[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5 \n",
    "# svd = TruncatedSVD(n_components = k)\n",
    "# latent_semantics = svd.fit_transform(data_color_moments)\n",
    "# print(\"Reduced Data:(Latent Semantics)\")\n",
    "# print(latent_semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD_calc(feature_matrix,k):\n",
    "    #print(\"Enter SVD calc\")\n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "    latent_semantics = svd.fit_transform(feature_matrix)\n",
    "    #print(\"The latent semantics are:\")\n",
    "    return latent_semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMF_calculator(feature_matrix,k):\n",
    "    nmf = NMF(n_components=k)\n",
    "    W = nmf.fit_transform(feature_matrix)\n",
    "    H = nmf.components_\n",
    "    return H "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_calculator(feature_matrix,k):\n",
    "    lda = LinearDiscriminantAnalysis(n_components = k)\n",
    "    lda_result = lda.fit_transform(feature_matrix,labels_caltech_101)\n",
    "    top_k_latent = lda.scalings_[:, :k]\n",
    "    return top_k_latent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_calculator(feature_matrix,k):\n",
    "    kmeans = KMeans(n_clusters = k,random_state=0)\n",
    "    kmeans.fit(feature_matrix)\n",
    "    top_k_latent_semantics = kmeans.cluster_centers_\n",
    "    return top_k_latent_semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below Is the Code Of Block of converting the Phase 1 results into feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# df_color_moments = pd.read_csv(\"color_moments_with_imageID.csv\")\n",
    "# feature_columns = df_color_moments.columns[1:-1]\n",
    "# data_color_moments = df_color_moments[feature_columns].values\n",
    "# print(feature_columns)\n",
    "# print(data_color_moments[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the Below code block use data_color_moments as the feature matrix for SVD \n",
    "#### Use the X_color_moments for NMF and X_standardized_color_moments for remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "color_moments_df = pd.DataFrame(color_moments_list)\n",
    "color_moments_df.fillna(color_moments_df.mean(), inplace=True)\n",
    "data_color_moments= color_moments_df.drop(columns=\"ImageID\").to_numpy()\n",
    "n_grids_per_image = 10 * 10  # 10x10 grid for each image\n",
    "n_features_per_grid = data_color_moments.shape[1]\n",
    "X_color_moments = data_color_moments.reshape(len(dataset), n_grids_per_image * n_features_per_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file_name = \"color_moments.csv\"\n",
    "# color_moments_df.to_csv(csv_file_name,index=False)\n",
    "# print(\"Color Moment DataFrame saved to\", csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2 = StandardScaler()\n",
    "X_standardized_color_moments = scaler_2.fit_transform(X_color_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_standardized_color_moments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n"
     ]
    }
   ],
   "source": [
    "print(len(X_color_moments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use X_hog for nmf and X_hog_standardized for remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_hog = np.array(list(hog_features_dict.values()))\n",
    "scaler = StandardScaler()\n",
    "X_hog_standardized = scaler.fit_transform(X_hog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_hog_standardized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Matrix Conversion of Resnet computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resnet_avgpool = np.array([entry[\"Output\"] for entry in output_avgpool_with_ids])\n",
    "X_resnet_layers3 = np.array([entry[\"Output\"] for entry in output_layers3_with_ids])\n",
    "X_resnet_fc = np.array([entry[\"Output\"] for entry in output_fc_with_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n"
     ]
    }
   ],
   "source": [
    "print(len(X_resnet_layers3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use X_resnet_{layer_value} for NMF and X_standardized_resnet_{layer_value} for remaining reduction technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the data \n",
    "scaler_1 = StandardScaler()\n",
    "X_standardized_resnet_avgpool = scaler_1.fit_transform(X_resnet_avgpool)\n",
    "X_standardized_resnet_layers3 = scaler_1.fit_transform(X_resnet_layers3)\n",
    "X_standardized_resnet_fc = scaler_1.fit_transform(X_resnet_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n"
     ]
    }
   ],
   "source": [
    "print(len(X_standardized_resnet_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_standardized_resnet_fc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create the UI here and call appropriate functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_model_data(feature_model):\n",
    "    if feature_model == \"Color Moments\":\n",
    "        X_data = X_color_moments\n",
    "        X_standardized = X_standardized_color_moments\n",
    "    elif feature_model == \"HOG Descriptor\":\n",
    "        X_data = X_hog\n",
    "        X_standardized = X_hog_standardized\n",
    "    elif  feature_model == \"Resnet FC\":\n",
    "        X_data = X_resnet_fc\n",
    "        X_standardized = X_standardized_resnet_fc\n",
    "    elif feature_model == \"Resnet Avgpool\":\n",
    "        X_data = X_resnet_avgpool\n",
    "        X_standardized= X_standardized_resnet_avgpool \n",
    "    elif feature_model == \"Resnet Layer 3\":\n",
    "        X_data = X_resnet_layers3\n",
    "        X_standardized= X_standardized_resnet_layers3\n",
    "    else:\n",
    "        return -1\n",
    "    return X_data,X_standardized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality_reduction(X_data,X_standardized,technique,k):\n",
    "    if technique == 'SVD':\n",
    "        #print(\"Entered SVD\")\n",
    "        result = SVD_calc(X_standardized,k)\n",
    "    elif technique == 'NNMF':\n",
    "        result = NMF_calculator(X_data,k)\n",
    "    elif technique =='LDA':\n",
    "        result = LDA_calculator(X_standardized,k)\n",
    "    elif technique == 'k-means':\n",
    "        result = k_means_calculator(X_standardized,k)\n",
    "    else :\n",
    "        return -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savetocsv(result,feature_model,k,technique_choice):\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = [f'LatentSemantic{i+1}' for i in range(df.shape[1])]\n",
    "\n",
    "    df['ImageID'] = range(len(df))\n",
    "\n",
    "    #Save file to CSV \n",
    "    filename = f\"{feature_model}_k{k}_{technique_choice}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(\"Output saved to\", filename)\n",
    "    #For each latent semantic order imageIDs by their weights \n",
    "    for i in range(min(df.shape[1],k)):\n",
    "        sorted_df = df[['ImageID', f'LatentSemantic{i+1}']].sort_values(by=f'LatentSemantic{i+1}', ascending=False)\n",
    "        print(f\"Top images for LatentSemantic{i+1}\")\n",
    "        print(sorted_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #Select a Feature Model\n",
    "    # Prompt user for feature model\n",
    "    print(\"Choose a feature model:\")\n",
    "    print(\"1. Color Moments\")\n",
    "    print(\"2. HOG Descriptor\")\n",
    "    print(\"3. Resnet FC\")\n",
    "    print(\"4. Resnet Avgpool\")\n",
    "    print(\"5. Resnet Layer 3\")\n",
    "    feature_model_choice = input(\"Enter your choice(number): \")\n",
    "    # Convert choice to string name\n",
    "    feature_model = [\"Color Moments\", \"HOG Descriptor\", \"Resnet FC\", \"Resnet Avgpool\", \"Resnet Layer 3\"][int(feature_model_choice) - 1]\n",
    "    #print(feature_model)\n",
    "    X_data, X_standardized_data = get_feature_model_data(feature_model)\n",
    "#Select the Dimensionality Reduction Technique \n",
    "    k = int(input('Please Enter the value of k'))\n",
    "    # Prompt user for dimensionality reduction technique\n",
    "    print(\"\\nChoose a dimensionality reduction technique:\")\n",
    "    print(\"1. SVD\")\n",
    "    print(\"2. NNMF\")\n",
    "    print(\"3. LDA\")\n",
    "    print(\"4. k-means\")\n",
    "    technique_choice = input(\"Enter your choice: \")\n",
    "    #Convert choice to specified string \n",
    "    technique = [\"SVD\", \"NNMF\", \"LDA\", \"k-means\"][int(technique_choice) - 1]\n",
    "    result = dimensionality_reduction(X_data,X_standardized_data,technique,k,)\n",
    "    savetocsv(result,feature_model,k,technique_choice)\n",
    "    # df = pd.DataFrame(result)\n",
    "    # print(df.shape[1])\n",
    "    # print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a feature model:\n",
      "1. Color Moments\n",
      "2. HOG Descriptor\n",
      "3. Resnet FC\n",
      "4. Resnet Avgpool\n",
      "5. Resnet Layer 3\n",
      "\n",
      "Choose a dimensionality reduction technique:\n",
      "1. SVD\n",
      "2. NNMF\n",
      "3. LDA\n",
      "4. k-means\n",
      "Output saved to Resnet FC_k10_1.csv\n",
      "Top images for LatentSemantic1\n",
      "      ImageID  LatentSemantic1\n",
      "6197     6197        54.812706\n",
      "5823     5823        54.019341\n",
      "3943     3943        51.321743\n",
      "5868     5868        50.859650\n",
      "5797     5797        50.431736\n",
      "Top images for LatentSemantic2\n",
      "      ImageID  LatentSemantic2\n",
      "1962     1962        31.668621\n",
      "2174     2174        28.875381\n",
      "2419     2419        27.720409\n",
      "2350     2350        27.538900\n",
      "2172     2172        26.885387\n",
      "Top images for LatentSemantic3\n",
      "      ImageID  LatentSemantic3\n",
      "6141     6141        29.444397\n",
      "373       373        29.394978\n",
      "281       281        29.165863\n",
      "366       366        28.910862\n",
      "6188     6188        28.582352\n",
      "Top images for LatentSemantic4\n",
      "      ImageID  LatentSemantic4\n",
      "7575     7575        19.309738\n",
      "3966     3966        18.531372\n",
      "1811     1811        17.688160\n",
      "8616     8616        17.286808\n",
      "2721     2721        16.799915\n",
      "Top images for LatentSemantic5\n",
      "      ImageID  LatentSemantic5\n",
      "1843     1843        17.374142\n",
      "1763     1763        16.665848\n",
      "1468     1468        15.636491\n",
      "1541     1541        15.431585\n",
      "1563     1563        15.337729\n",
      "Top images for LatentSemantic6\n",
      "      ImageID  LatentSemantic6\n",
      "1058     1058        20.342749\n",
      "879       879        17.014933\n",
      "906       906        16.457676\n",
      "6990     6990        16.385019\n",
      "892       892        16.001760\n",
      "Top images for LatentSemantic7\n",
      "      ImageID  LatentSemantic7\n",
      "3423     3423        14.659593\n",
      "7368     7368        12.827385\n",
      "1140     1140        11.158884\n",
      "1739     1739        10.983290\n",
      "1805     1805        10.762575\n",
      "Top images for LatentSemantic8\n",
      "      ImageID  LatentSemantic8\n",
      "7103     7103        14.949694\n",
      "3252     3252        14.153708\n",
      "3292     3292        13.811666\n",
      "7104     7104        13.214808\n",
      "6204     6204        13.043355\n",
      "Top images for LatentSemantic9\n",
      "      ImageID  LatentSemantic9\n",
      "5870     5870        16.727634\n",
      "3967     3967        15.594440\n",
      "3691     3691        13.865460\n",
      "6168     6168        13.802445\n",
      "3964     3964        13.349911\n",
      "Top images for LatentSemantic10\n",
      "      ImageID  LatentSemantic10\n",
      "7719     7719         13.462905\n",
      "6251     6251         12.082409\n",
      "6287     6287         11.130354\n",
      "4125     4125         11.074192\n",
      "2035     2035         11.011987\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
