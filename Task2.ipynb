{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0240eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8677\n",
      "[  0   0   0 ... 100 100 100]\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import math\n",
    "import numpy as np \n",
    "import shutil\n",
    "\n",
    "from torchvision.models.resnet import *\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "\n",
    "import pandas as pd\n",
    "from split_image import split_image\n",
    "\n",
    "\n",
    "\n",
    "#load dataset\n",
    "dataset = torchvision.datasets.Caltech101(\"../CSE515-Project/\")\n",
    "labels_caltech_101 = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "downdata_loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True, num_workers=8)\n",
    "print(len(dataset))\n",
    "\n",
    "print(labels_caltech_101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57933f0",
   "metadata": {},
   "source": [
    " Task 2a: Implement a program which, given (a) a query imageID or image file, (b) a user selected feature space, and\n",
    "(c) positive integer k, identifies and lists k most likely matching labels, along with their scores, under the selected\n",
    "feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19920d16",
   "metadata": {},
   "source": [
    "Key for selecting query type and feature space type\n",
    "\n",
    "Query Type- \n",
    "- i : Image ID Query\n",
    "- f: Image File Query\n",
    "\n",
    "Feature Space Type- \n",
    "- 1 : Color Moment\n",
    "- 2 : HoG\n",
    "- 3 : ResNet-AvgPool-1024\n",
    "- 4 : ResNet-Layer3-1024\n",
    "- 5 : ResNet-FC-1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9415d380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvalid = False\\nfeatureSpaceType = input(\"Enter the number to the feature space you would like to use: (1) Color Moment; (2) HoG; (3) ResNet-AvgPool-1024; (4) ResNet-Layer3-1024; (5) ResNet-FC-1000\")\\nif(featureSpaceType != \"1\" and featureSpaceType != \"2\" and featureSpaceType != \"3\" and featureSpaceType != \"4\"and featureSpaceType != \"5\"):\\n    while(not valid):\\n        featureSpaceType = input(\"Please enter a valid query type:\\nEnter the number to the feature space you would like to use: (1) Color Moment; (2) HoG; (3) ResNet-AvgPool-1024; (4) ResNet-Layer3-1024; (5) ResNet-FC-1000\")\\n        if(featureSpaceType == \"1\" or featureSpaceType == \"2\" or featureSpaceType == \"3\" or featureSpaceType == \"4\" or featureSpaceType == \"5\"):\\n            valid = True\\nprint(\"Feature Space type: \" + featureSpaceTypeDict[featureSpaceType])\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get inputs for Task 2:\n",
    "#type of query, feature space, k\n",
    "valid = False\n",
    "img = dataset[0][0]\n",
    "\n",
    "'''\n",
    "queryTypeDict = {\"i\": \"Image ID Query\", \"f\" : \"Image File Query\"}\n",
    "featureSpaceTypeDict = {\"1\": \"Color Moment\", \"2\": \"HoG\", \"3\" : \"ResNet-AvgPool-1024\", \"4\" : \"ResNet-Layer3-1024\", \"5\" : \"ResNet-FC-1000\"}\n",
    "\n",
    "queryType = input(\"Enter \\\"i\\\" for image ID query, and \\\"f\\\" for image file query\")\n",
    "if(queryType != \"i\" and queryType != \"f\"):\n",
    "    while(not valid):\n",
    "        queryType = input(\"Please enter a valid query type:\\nEnter \\\"i\\\" for image ID query, and \\\"f\\\" for image file query\")\n",
    "        if(queryType == \"i\" or queryType == \"f\"):\n",
    "            valid = True\n",
    "print(\"Input type: \" + queryTypeDict[queryType])\n",
    "\n",
    "\n",
    "if queryType == \"i\":\n",
    "    caltechID = input(\"Enter an image ID (from 0-8676)\")\n",
    "    img = dataset[int(caltechID)][0]\n",
    "'''\n",
    "#caltechID = input(\"Enter an image ID (from 0-8676)\")\n",
    "#img = dataset[int(caltechID)][0]\n",
    "\n",
    "''' \n",
    "imageFileName = input(\"Please enter the path for the desired image\")\n",
    "img = imread(imageFileName)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "'''\n",
    "#print(\"Shape:\" + str(img.shape))\n",
    "\n",
    "'''\n",
    "valid = False\n",
    "featureSpaceType = input(\"Enter the number to the feature space you would like to use: (1) Color Moment; (2) HoG; (3) ResNet-AvgPool-1024; (4) ResNet-Layer3-1024; (5) ResNet-FC-1000\")\n",
    "if(featureSpaceType != \"1\" and featureSpaceType != \"2\" and featureSpaceType != \"3\" and featureSpaceType != \"4\"and featureSpaceType != \"5\"):\n",
    "    while(not valid):\n",
    "        featureSpaceType = input(\"Please enter a valid query type:\\nEnter the number to the feature space you would like to use: (1) Color Moment; (2) HoG; (3) ResNet-AvgPool-1024; (4) ResNet-Layer3-1024; (5) ResNet-FC-1000\")\n",
    "        if(featureSpaceType == \"1\" or featureSpaceType == \"2\" or featureSpaceType == \"3\" or featureSpaceType == \"4\" or featureSpaceType == \"5\"):\n",
    "            valid = True\n",
    "print(\"Feature Space type: \" + featureSpaceTypeDict[featureSpaceType])\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5b6e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorMoment(img):\n",
    "    #resize image\n",
    "    imOpen = np.asarray(img)\n",
    "\n",
    "    resizedImg = resize(imOpen, (100,300))\n",
    "    #plt.imshow(resizedImg)\n",
    "    #plt.show()\n",
    "    #print(\"Shape:\" + str(resizedImg.shape))\n",
    "    matplotlib.image.imsave('resized.jpg', resizedImg)\n",
    "\n",
    "\n",
    "    #partition images into 10x10 grid\n",
    "    splitDir = \"./split\"\n",
    "    os.makedirs(splitDir)\n",
    "    split_image('./resized.jpg', 10, 10, False, False, True, splitDir)\n",
    "\n",
    "\n",
    "    colorMoment = torch.Tensor(10, 10, 3, 3) \n",
    "    #iterate through grid    squares and calculate the color moment for each\n",
    "    xGrid = 0\n",
    "    yGrid = 0\n",
    "    for gridSquare in os.listdir(splitDir):\n",
    "        if xGrid >= 10:\n",
    "            xGrid = 0\n",
    "            yGrid += 1\n",
    "        \n",
    "        gridImg = imread(splitDir + '/' + gridSquare)\n",
    "        rAvg = 0\n",
    "        gAvg = 0\n",
    "        bAvg = 0\n",
    "\n",
    "        #calculate mean\n",
    "        for x in range(gridImg.shape[1]):\n",
    "            for y in range(gridImg.shape[0]):\n",
    "                rAvg += gridImg[y][x][0]\n",
    "                gAvg += gridImg[y][x][1]\n",
    "                bAvg += gridImg[y][x][2]\n",
    "\n",
    "        rAvg = rAvg/300\n",
    "        gAvg = gAvg/300\n",
    "        bAvg = bAvg/300\n",
    "\n",
    "        #calculage standard deviation and skew\n",
    "        rStdDevSum = 0\n",
    "        gStdDevSum = 0\n",
    "        bStdDevSum = 0\n",
    "\n",
    "        rSkewSum = 0\n",
    "        gSkewSum = 0\n",
    "        bSkewSum = 0\n",
    "\n",
    "        for x in range(gridImg.shape[1]):\n",
    "            for y in range(gridImg.shape[0]):\n",
    "                rStdDevSum += pow(gridImg[y][x][0] - rAvg, 2)\n",
    "                gStdDevSum += pow(gridImg[y][x][1] - gAvg, 2)\n",
    "                bStdDevSum += pow(gridImg[y][x][2] - bAvg, 2)\n",
    "\n",
    "                rSkewSum += pow(gridImg[y][x][0] - rAvg, 3)\n",
    "                gSkewSum += pow(gridImg[y][x][1] - gAvg, 3)\n",
    "                bSkewSum += pow(gridImg[y][x][2] - bAvg, 3)\n",
    "\n",
    "        rStdDev = math.sqrt(rStdDevSum/300)\n",
    "        gStdDev = math.sqrt(gStdDevSum/300)\n",
    "        bStdDev = math.sqrt(bStdDevSum/300)\n",
    "\n",
    "        rSkew = np.cbrt((rSkewSum/300))\n",
    "        gSkew = np.cbrt((gSkewSum/300))\n",
    "        bSkew = np.cbrt((bSkewSum/300))\n",
    "\n",
    "        colorMoment[xGrid][yGrid][0] = torch.tensor([rAvg, rStdDev, rSkew])\n",
    "        colorMoment[xGrid][yGrid][1] = torch.tensor([gAvg, gStdDev, gSkew])\n",
    "        colorMoment[xGrid][yGrid][2] = torch.tensor([bAvg, bStdDev, bSkew])\n",
    "\n",
    "        xGrid += 1\n",
    "\n",
    "    #remove temporary files\n",
    "    shutil.rmtree(splitDir)\n",
    "    os.remove(\"resized.jpg\")\n",
    "\n",
    "    return colorMoment\n",
    "\n",
    "def hogFunct(img):\n",
    "      \n",
    "\t#resize image\n",
    "    imOpen = np.asarray(img)\n",
    "\t#imOpen = np.asarray(dataset[id][0])\n",
    "\n",
    "    resizedImg = resize(imOpen, (100,300))\n",
    "    matplotlib.image.imsave('resized.jpg', resizedImg)\n",
    "\n",
    "    resized_hog_img_np = imread('./resized.jpg')\n",
    "    grayscaleResizedHogImg = cv2.cvtColor(resized_hog_img_np,cv2.COLOR_BGR2GRAY)\n",
    "    plt.show()\n",
    "\n",
    "    cv2.imwrite(\"greyscaleImg.png\", grayscaleResizedHogImg)\n",
    "    os.remove(\"resized.jpg\")\n",
    "\n",
    "    gridIm = imread(\"greyscaleImg.png\")\n",
    "    fd, hog_image = hog(gridIm, orientations=9, pixels_per_cell=(10,30),\n",
    "                        cells_per_block=(1, 1), visualize=True, channel_axis=None, feature_vector=False)\n",
    "    #plt.axis(\"off\")\n",
    "    #plt.imshow(hog_image, cmap=\"gray\")\n",
    "    #print(fd.shape)\n",
    "\n",
    "    os.remove(\"greyscaleImg.png\")\n",
    "\n",
    "    hogTensor = torch.Tensor(10,10,9)\n",
    "    for y in range(10):\n",
    "        for x in range(10):\n",
    "            hogTensor[x][y] = torch.tensor(fd[x][y][0][0])\n",
    "    return hogTensor\n",
    "\n",
    "def resnetAvgPool(img):\n",
    "    #dictionary storing layer outputs\n",
    "    layer_outputs = {\n",
    "        'layer3': [],\n",
    "        'avgpool': [],\n",
    "        'fc': []\n",
    "    }\n",
    "\n",
    "    def get_intermediate_outputs(layer):\n",
    "        def hook(model, input, output):\n",
    "            layer_outputs[layer] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    #resize image\n",
    "    imOpen = np.asarray(img)\n",
    "\n",
    "    resizedImg = resize(imOpen, (224,224))\n",
    "    matplotlib.image.imsave('resized.jpg', resizedImg)\n",
    "    resizedImgNp = imread('./resized.jpg')\n",
    "\n",
    "    npDataset = torch.tensor([np.transpose(resizedImgNp)])\n",
    "    #print(\"Shape:\" + str(npDataset.shape))\n",
    "\n",
    "    rn_model =  torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    rn_model.eval()\n",
    "    rn_model.avgpool.register_forward_hook(get_intermediate_outputs('avgpool'))\n",
    "    rn_model(npDataset.float())\n",
    "\n",
    "    avgpoolAveraged = torch.Tensor(1,1024) \n",
    "\n",
    "    #average out avgpool layer\n",
    "    for i in range(1024):\n",
    "        avgpoolAveraged[0][i] = (layer_outputs['avgpool'][0][2 * i][0][0] + layer_outputs['avgpool'][0][2 * i + 1][0][0])/2\n",
    "    layer_outputs['avgpool'] = avgpoolAveraged\n",
    "\n",
    "    #print(layer_outputs['avgpool'].shape)\n",
    "    os.remove(\"resized.jpg\")\n",
    "\n",
    "    return layer_outputs['avgpool']\n",
    "\n",
    "def resnetfc(img):\n",
    "    #dictionary storing layer outputs\n",
    "    layer_outputs = {\n",
    "        'layer3': [],\n",
    "        'avgpool': [],\n",
    "        'fc': []\n",
    "    }\n",
    "\n",
    "    def get_intermediate_outputs(layer):\n",
    "        def hook(model, input, output):\n",
    "            layer_outputs[layer] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    #resize image\n",
    "    imOpen = np.asarray(img)\n",
    "\n",
    "    resizedImg = resize(imOpen, (224,224))\n",
    "    #print(\"Shape:\" + str(resizedImg.shape))\n",
    "    matplotlib.image.imsave('resized.jpg', resizedImg)\n",
    "    resizedImgNp = imread('./resized.jpg')\n",
    "\n",
    "    npDataset = torch.tensor([np.transpose(resizedImgNp)])\n",
    "    #print(\"Shape:\" + str(npDataset.shape))\n",
    "\n",
    "    rn_model =  torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    rn_model.eval()\n",
    "    rn_model.fc.register_forward_hook(get_intermediate_outputs('fc'))\n",
    "    rn_model(npDataset.float())\n",
    "\n",
    "    #print(layer_outputs['fc'].shape)\n",
    "\n",
    "    os.remove(\"resized.jpg\")\n",
    "\n",
    "    return layer_outputs['fc']\n",
    "\n",
    "def resnetLayer3(img):\n",
    "    #dictionary storing layer outputs\n",
    "    layer_outputs = {\n",
    "        'layer3': [],\n",
    "        'avgpool': [],\n",
    "        'fc': []\n",
    "    }\n",
    "\n",
    "    def get_intermediate_outputs(layer):\n",
    "        def hook(model, input, output):\n",
    "            layer_outputs[layer] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    #resize image\n",
    "    imOpen = np.asarray(img)\n",
    "\n",
    "    resizedImg = resize(imOpen, (224,224))\n",
    "    matplotlib.image.imsave('resized.jpg', resizedImg)\n",
    "    resizedImgNp = imread('./resized.jpg')\n",
    "\n",
    "    npDataset = torch.tensor([np.transpose(resizedImgNp)])\n",
    "    #print(\"Shape:\" + str(npDataset.shape))\n",
    "\n",
    "    rn_model =  torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    rn_model.eval()\n",
    "    rn_model.layer3.register_forward_hook(get_intermediate_outputs('layer3'))\n",
    "    rn_model(npDataset.float())\n",
    "\n",
    "    #average slices of layer3\n",
    "    layer3Averaged = torch.Tensor.numpy(layer_outputs['layer3'])\n",
    "    layer3Averaged = np.mean(layer3Averaged, axis = (2,3))\n",
    "    layer_outputs['layer3'] = torch.tensor(layer3Averaged)\n",
    "\n",
    "    #print(layer_outputs['layer3'].shape)\n",
    "    os.remove(\"resized.jpg\")\n",
    "\n",
    "    return layer_outputs['layer3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e9a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load existing output data\n",
    "colorMomentDict = torch.load(\"ptOutputs/colorMoment_output.pt\")\n",
    "hogDict = torch.load(\"ptOutputs/hog_output.pt\")\n",
    "avgpoolDict = torch.load(\"ptOutputs/avgpool_output.pt\")\n",
    "fcDict = torch.load(\"ptOutputs/fc_output.pt\")\n",
    "layer3Dict = torch.load(\"ptOutputs/layer3_output.pt\")\n",
    "\n",
    "def calculateColorMomentDistanceVector(count):\n",
    "    colorMomentCurrent = colorMoment(dataset[int(caltechID)][0])\n",
    "\n",
    "    #create list of tupes (id, distance), sorted by distance from lowest to highest\n",
    "    kSimilarImage = []\n",
    "    for i in range(count):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(colorMomentCurrent) - torch.Tensor.numpy(colorMomentDict[str(i)]))\n",
    "        kSimilarImage.append((i, dist))\n",
    "        #print(dist)\n",
    "    kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    for i in range(count, len(dataset)):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(colorMomentCurrent) - torch.Tensor.numpy(colorMomentDict[str(i)]))\n",
    "        if dist < kSimilarImage[count-1][1]:\n",
    "            kSimilarImage.pop()\n",
    "            kSimilarImage.append((i, dist))\n",
    "            kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i in range(count):\n",
    "        fig.add_subplot(5, 2, i+1)\n",
    "        im =  np.asarray(dataset[kSimilarImage[i][0]][0])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(im)\n",
    "        plt.title(kSimilarImage[i][0])\n",
    "\n",
    "    return kSimilarImage\n",
    "\n",
    "def calculateHOGDistanceVector(count):\n",
    "    hogCurrent = hogFunct(dataset[int(caltechID)][0])\n",
    "\n",
    "    #create list of tupes (id, distance), sorted by distance from lowest to highest\n",
    "    kSimilarImage = []\n",
    "    for i in range(count):\n",
    "        dist = np.linalg.norm(hogCurrent - torch.Tensor.numpy(hogDict[str(i)]))\n",
    "        kSimilarImage.append((i, dist))\n",
    "        #print(dist)\n",
    "    kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    for i in range(count, len(dataset)):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(hogCurrent) - torch.Tensor.numpy(hogDict[str(i)]))\n",
    "        if dist < kSimilarImage[count-1][1]:\n",
    "            kSimilarImage.pop()\n",
    "            kSimilarImage.append((i, dist))\n",
    "            kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i in range(count):\n",
    "        fig.add_subplot(5, 2, i+1)\n",
    "        im =  np.asarray(dataset[kSimilarImage[i][0]][0])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(im)\n",
    "        plt.title(kSimilarImage[i][0])\n",
    "\n",
    "    return kSimilarImage\n",
    "\n",
    "def calculateAvgpoolDistanceVector(count):\n",
    "    avgpoolCurrent = resnetAvgPool(dataset[int(caltechID)][0])\n",
    "    \n",
    "    #create list of tupes (id, distance), sorted by distance from lowest to highest\n",
    "    kSimilarImage = []\n",
    "    for i in range(count):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(avgpoolCurrent) - torch.Tensor.numpy(avgpoolDict[str(i)]))\n",
    "        kSimilarImage.append((i, dist))\n",
    "        #print(dist)\n",
    "    kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    for i in range(count, len(dataset)):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(avgpoolCurrent) - torch.Tensor.numpy(avgpoolDict[str(i)]))\n",
    "        if dist < kSimilarImage[count-1][1]:\n",
    "            kSimilarImage.pop()\n",
    "            kSimilarImage.append((i, dist))\n",
    "            kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i in range(count):\n",
    "        fig.add_subplot(5, 2, i+1)\n",
    "        im =  np.asarray(dataset[kSimilarImage[i][0]][0])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(im)\n",
    "        plt.title(str(i+1) + \") \" + str(kSimilarImage[i][0]))\n",
    "    return kSimilarImage\n",
    "\n",
    "def calculateFcDistanceVector(count):\n",
    "    fcDictCurrent = resnetfc(dataset[int(caltechID)][0])\n",
    "    \n",
    "    #create list of tupes (id, distance), sorted by distance from lowest to highest\n",
    "    kSimilarImage = []\n",
    "    for i in range(count):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(fcDictCurrent) - torch.Tensor.numpy(fcDict[str(i)]))\n",
    "        kSimilarImage.append((i, dist))\n",
    "        #print(dist)\n",
    "    kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    for i in range(count, len(dataset)):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(fcDictCurrent) - torch.Tensor.numpy(fcDict[str(i)]))\n",
    "        if dist < kSimilarImage[count-1][1]:\n",
    "            kSimilarImage.pop()\n",
    "            kSimilarImage.append((i, dist))\n",
    "            kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i in range(count):\n",
    "        fig.add_subplot(5, 2, i+1)\n",
    "        im =  np.asarray(dataset[kSimilarImage[i][0]][0])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(im)\n",
    "        plt.title(kSimilarImage[i][0])\n",
    "\n",
    "    return kSimilarImage\n",
    "\n",
    "def calculateLayer3DistanceVector(count):\n",
    "    layer3DictCurrent = resnetLayer3(dataset[int(caltechID)][0])\n",
    "\n",
    "    #create list of tupes (id, distance), sorted by distance from lowest to highest\n",
    "    kSimilarImage = []\n",
    "    for i in range(count):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(layer3DictCurrent) - torch.Tensor.numpy(layer3Dict[str(i)]))\n",
    "        kSimilarImage.append((i, dist))\n",
    "        #print(dist)\n",
    "    kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    for i in range(count, len(dataset)):\n",
    "        dist = np.linalg.norm(torch.Tensor.numpy(layer3DictCurrent) - torch.Tensor.numpy(layer3Dict[str(i)]))\n",
    "        if dist < kSimilarImage[count-1][1]:\n",
    "            kSimilarImage.pop()\n",
    "            kSimilarImage.append((i, dist))\n",
    "            kSimilarImage.sort(key = lambda x:x[1])\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i in range(count):\n",
    "        fig.add_subplot(5, 2, i+1)\n",
    "        im =  np.asarray(dataset[kSimilarImage[i][0]][0])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(im)\n",
    "        plt.title(kSimilarImage[i][0])\n",
    "\n",
    "    return kSimilarImage\n",
    "\n",
    "#calculateHOGDistanceVector(3)\n",
    "#calculateColorMomentDistanceVector(3)\n",
    "#calculateFcDistanceVector(3)\n",
    "#calculateAvgpoolDistanceVector(3)\n",
    "#calculateLayer3DistanceVector(3)\n",
    "\n",
    "#img = imread(\"./13.png\")\n",
    "#print(colorMoment(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dda35b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean\n",
    "def calculateColorMomentMean(img):\n",
    "    colorMomentResult = colorMoment(img)\n",
    "    mean = colorMomentResult.flatten().mean()\n",
    "    return mean\n",
    "    \n",
    "def calculateHOGMean(img):\n",
    "    hogResult = hogFunct(img)\n",
    "    mean = hogResult.flatten().mean()\n",
    "    return mean\n",
    "\n",
    "def calculateAvgPoolMean(img):\n",
    "    avgPoolResult = resnetAvgPool(img)\n",
    "    mean = avgPoolResult.flatten().mean()\n",
    "    print(mean)\n",
    "    return mean\n",
    "\n",
    "def calculateLayer3Mean(img):\n",
    "    layer3Result = resnetLayer3(img)\n",
    "    mean = layer3Result.flatten().mean()\n",
    "    print(mean)\n",
    "    return mean\n",
    "\n",
    "def calculateFcMean(img):\n",
    "    fcResult = resnetfc(img)\n",
    "    mean = fcResult.flatten().mean()\n",
    "    return mean\n",
    "\n",
    "#calculate clusters\n",
    "def calculateCluster():\n",
    "    colorMomentCluster = {}\n",
    "    HOGCluster = {}\n",
    "    avgPoolCluster = {}\n",
    "    fcCluster = {}\n",
    "    layer3Cluster = {}\n",
    "\n",
    "    for i in range(len(10)):\n",
    "        cmMean = np.ndarray.mean(colorMomentDict[str(i)].numpy())\n",
    "        colorMomentCluster[str(i)] = cmMean\n",
    "\n",
    "    torch.save(colorMomentCluster, \"./colorMoment_output.pt\")\n",
    "    torch.save(HOGCluster, \"./hog_output.pt\")\n",
    "    torch.save(avgPoolCluster, \"./avgpool_output.pt\")\n",
    "    torch.save(fcCluster, \"./fc_output.pt\")\n",
    "    torch.save(layer3Cluster, \"./layer3_output.pt\")\n",
    "\n",
    "def calculateColorMomentCluster():\n",
    "    colorMomentCluster = {}\n",
    "    labelNum = 0\n",
    "    clusterNpArray = np.array([colorMomentDict[str(0)].numpy().flatten()])\n",
    "    for i in range(1,len(dataset)):\n",
    "        if labels_caltech_101[i] == labelNum:\n",
    "            #clusterNpArray = np.stack((clusterNpArray, colorMomentDict[str(i)].numpy().flatten()))\n",
    "            clusterNpArray = np.vstack((clusterNpArray, np.array([colorMomentDict[str(i)].numpy().flatten()])))\n",
    "        else: \n",
    "            #print(clusterNpArray.shape)\n",
    "            colorMomentCluster[str(labelNum)] = clusterNpArray.mean()\n",
    "            clusterNpArray = np.array([colorMomentDict[str(i)].numpy().flatten()])\n",
    "            labelNum = labels_caltech_101[i]\n",
    "\n",
    "    torch.save(colorMomentCluster, \"ptOutputs/colorMoment_labelValues.pt\")\n",
    "    \n",
    "    print(colorMomentCluster)\n",
    "\n",
    "def calculateHOGCluster():\n",
    "    HOGCluster = {}\n",
    "    labelNum = 0\n",
    "    clusterNpArray = np.array([hogDict[str(0)].numpy().flatten()])\n",
    "    for i in range(1,len(dataset)):\n",
    "        if labels_caltech_101[i] == labelNum:\n",
    "            clusterNpArray = np.vstack((clusterNpArray, np.array([hogDict[str(i)].numpy().flatten()])))\n",
    "        else: \n",
    "            #print(clusterNpArray.shape)\n",
    "            HOGCluster[str(labelNum)] = clusterNpArray.mean()\n",
    "            clusterNpArray = np.array([hogDict[str(i)].numpy().flatten()])\n",
    "            labelNum = labels_caltech_101[i]\n",
    "\n",
    "    torch.save(HOGCluster, \"ptOutputs/hog_labelValues.pt\")\n",
    "    \n",
    "    print(HOGCluster)\n",
    "\n",
    "def calculateAvgPoolCluster():\n",
    "    avgPoolCluster = {}\n",
    "    labelNum = 0\n",
    "    clusterNpArray = np.array([avgpoolDict[str(0)].numpy().flatten()])\n",
    "    for i in range(1,len(dataset)):\n",
    "        if labels_caltech_101[i] == labelNum:\n",
    "            clusterNpArray = np.vstack((clusterNpArray, np.array([avgpoolDict[str(i)].numpy().flatten()])))\n",
    "        else: \n",
    "            #print(clusterNpArray.shape)\n",
    "            avgPoolCluster[str(labelNum)] = clusterNpArray.mean()\n",
    "            clusterNpArray = np.array([avgpoolDict[str(i)].numpy().flatten()])\n",
    "            labelNum = labels_caltech_101[i]\n",
    "\n",
    "    torch.save(avgPoolCluster, \"ptOutputs/avgpool_labelValues.pt\")\n",
    "    \n",
    "    print(avgPoolCluster)\n",
    "\n",
    "def calculateLayer3Cluster():\n",
    "    layer3Cluster = {}\n",
    "    labelNum = 0\n",
    "    clusterNpArray = np.array([layer3Dict[str(0)].numpy().flatten()])\n",
    "    for i in range(1,len(dataset)):\n",
    "        if labels_caltech_101[i] == labelNum:\n",
    "            clusterNpArray = np.vstack((clusterNpArray, np.array([layer3Dict[str(i)].numpy().flatten()])))\n",
    "        else: \n",
    "            #print(clusterNpArray.shape)\n",
    "            layer3Cluster[str(labelNum)] = clusterNpArray.mean()\n",
    "            clusterNpArray = np.array([layer3Dict[str(i)].numpy().flatten()])\n",
    "            labelNum = labels_caltech_101[i]\n",
    "\n",
    "    torch.save(layer3Cluster, \"ptOutputs/layer3_labelValues.pt\")\n",
    "    \n",
    "    print(layer3Cluster)\n",
    "\n",
    "def calculateFcCluster():\n",
    "    fcCluster = {}\n",
    "    labelNum = 0\n",
    "    clusterNpArray = np.array([fcDict[str(0)].numpy().flatten()])\n",
    "    for i in range(1,len(dataset)):\n",
    "        if labels_caltech_101[i] == labelNum:\n",
    "            clusterNpArray = np.vstack((clusterNpArray, np.array([fcDict[str(i)].numpy().flatten()])))\n",
    "        else: \n",
    "            #print(clusterNpArray.shape)\n",
    "            fcCluster[str(labelNum)] = clusterNpArray.mean()\n",
    "            clusterNpArray = np.array([fcDict[str(i)].numpy().flatten()])\n",
    "            labelNum = labels_caltech_101[i]\n",
    "\n",
    "    torch.save(fcCluster, \"ptOutputs/fc_labelValues.pt\")\n",
    "    \n",
    "    print(fcCluster)\n",
    "\n",
    "#calculate and save results of all clusters (have been previously run and outputs are stored)\n",
    "#calculateColorMomentCluster()\n",
    "#calculateHOGCluster()\n",
    "#calculateAvgPoolCluster()\n",
    "#calculateLayer3Cluster()\n",
    "#calculateFcCluster()\n",
    "\n",
    "#calculateColorMomentMean(imread(\"13.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53ee607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 47.797604, '1': 49.436893, '2': 37.94642, '3': 69.06228, '4': 44.615192, '5': 53.31274, '6': 53.89355, '7': 50.87424, '8': 49.28631, '9': 49.20733, '10': 50.294205, '11': 57.24651, '12': 52.62897, '13': 50.559128, '14': 59.14859, '15': 51.05956, '16': 51.255238, '17': 60.956272, '18': 51.905796, '19': 41.581264, '20': 54.32429, '21': 51.12832, '22': 54.539795, '23': 49.5021, '24': 49.880802, '25': 49.08988, '26': 52.8299, '27': 52.52218, '28': 46.950523, '29': 46.21784, '30': 54.955177, '31': 54.071774, '32': 60.25779, '33': 47.09667, '34': 53.41415, '35': 49.834988, '36': 49.42446, '37': 49.556362, '38': 59.14434, '39': 50.29117, '40': 52.902035, '41': 46.99145, '42': 43.5711, '43': 61.131554, '44': 48.76995, '45': 55.81151, '46': 56.283154, '47': 44.631878, '48': 66.187256, '49': 50.169003, '50': 54.27138, '51': 44.44393, '52': 64.24324, '53': 48.85292, '54': 47.427456, '55': 59.194275, '56': 52.620018, '57': 55.81866, '58': 49.25713, '59': 56.19961, '60': 43.329155, '61': 49.687275, '62': 45.373425, '63': 58.640408, '64': 53.985287, '65': 43.7409, '66': 46.29887, '67': 51.376286, '68': 51.83425, '69': 48.737507, '70': 53.582127, '71': 55.62505, '72': 57.04386, '73': 53.59599, '74': 53.544235, '75': 59.35147, '76': 48.097504, '77': 57.477165, '78': 52.923214, '79': 58.122322, '80': 60.937065, '81': 54.424034, '82': 43.27005, '83': 61.577072, '84': 56.68081, '85': 62.836098, '86': 55.543083, '87': 51.374874, '88': 60.036987, '89': 48.814312, '90': 49.4028, '91': 61.158714, '92': 40.258064, '93': 63.304554, '94': 58.974728, '95': 40.859745, '96': 55.34208, '97': 51.340992, '98': 58.65923, '99': 65.37652}\n"
     ]
    }
   ],
   "source": [
    "colorMoment_labels = torch.load(\"ptOutputs/colorMoment_labelValues.pt\")\n",
    "hog_labels = torch.load(\"ptOutputs/hog_labelValues.pt\")\n",
    "avgpool_labels = torch.load(\"ptOutputs/avgpool_labelValues.pt\")\n",
    "layer3_labels = torch.load(\"ptOutputs/layer3_labelValues.pt\")\n",
    "fc_labels = torch.load(\"ptOutputs/fc_labelValues.pt\")\n",
    "\n",
    "print(colorMoment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "700e331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xinhw\\AppData\\Local\\Temp\\ipykernel_40276\\2566171194.py:208: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  npDataset = torch.tensor([np.transpose(resizedImgNp)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.0663)\n",
      "[(1, 1.7957000732421875), (0, 2.720104217529297), (2, 2.7758989334106445), (8, 6.5151262283325195), (9, 8.794766426086426), (7, 8.82779598236084), (6, 21.176982879638672), (4, 21.71646499633789), (5, 23.140228271484375), (3, 28.741729736328125)]\n",
      "[(29, 0.11075973510742188), (28, 0.4581117630004883), (54, 0.4605369567871094), (51, 0.46695518493652344), (37, 0.4854421615600586), (44, 0.6182794570922852), (49, 1.4723052978515625), (1, 1.7957000732421875), (62, 2.0482959747314453), (58, 2.45792293548584)]\n"
     ]
    }
   ],
   "source": [
    "def getKMatchingLabels(img, k, model):\n",
    "    kSimilarLabels = []\n",
    "    if(model == \"1\"): #color moment\n",
    "        mean = calculateColorMomentMean(img)\n",
    "        for i in range(k):\n",
    "            diff = abs(colorMoment_labels[str(i)] - mean)\n",
    "            kSimilarLabels.append((i, diff.item()))\n",
    "        kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        #print(kSimilarLabels)\n",
    "\n",
    "        for i in range(k, 100):\n",
    "            diff = abs(colorMoment_labels[str(i)] - mean)\n",
    "            if diff < kSimilarLabels[k-1][1]:\n",
    "                kSimilarLabels.pop()\n",
    "                kSimilarLabels.append((i, diff.item()))\n",
    "                kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        print(kSimilarLabels)\n",
    "            \n",
    "    elif(model == \"2\"): #hog\n",
    "        mean = calculateHOGMean(img)\n",
    "        for i in range(k):\n",
    "            diff = abs(hog_labels[str(i)] - mean)\n",
    "            kSimilarLabels.append((i, diff.item()))\n",
    "        kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        #print(kSimilarLabels)\n",
    "\n",
    "        for i in range(k, 100):\n",
    "            diff = abs(hog_labels[str(i)] - mean)\n",
    "            if diff < kSimilarLabels[k-1][1]:\n",
    "                kSimilarLabels.pop()\n",
    "                kSimilarLabels.append((i, diff.item()))\n",
    "                kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        print(kSimilarLabels)     \n",
    "    elif(model == \"3\"): #avgpool\n",
    "        mean = calculateAvgPoolMean(img)\n",
    "        for i in range(k):\n",
    "            diff = abs(avgpool_labels[str(i)] - mean)\n",
    "            kSimilarLabels.append((i, diff.item()))\n",
    "        kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        #print(kSimilarLabels)\n",
    "\n",
    "        for i in range(k, 100):\n",
    "            diff = abs(avgpool_labels[str(i)] - mean)\n",
    "            if diff < kSimilarLabels[k-1][1]:\n",
    "                kSimilarLabels.pop()\n",
    "                kSimilarLabels.append((i, diff.item()))\n",
    "                kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        #print(kSimilarLabels)    \n",
    "    elif(model == \"4\"): #layer 3\n",
    "        mean = calculateLayer3Mean(img)\n",
    "        for i in range(k):\n",
    "            diff = abs(layer3_labels[str(i)] - mean)\n",
    "            kSimilarLabels.append((i, diff.item()))\n",
    "        kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        print(kSimilarLabels)\n",
    "\n",
    "        for i in range(k, 100):\n",
    "            diff = abs(layer3_labels[str(i)] - mean)\n",
    "            if diff < kSimilarLabels[k-1][1]:\n",
    "                kSimilarLabels.pop()\n",
    "                kSimilarLabels.append((i, diff.item()))\n",
    "                kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        print(kSimilarLabels)  \n",
    "    elif(model == \"5\"): #fc\n",
    "        mean = calculateFcCluster(img)\n",
    "        for i in range(k):\n",
    "            diff = abs(fc_labels[str(i)] - mean)\n",
    "            kSimilarLabels.append((i, diff.item()))\n",
    "        kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        #print(kSimilarLabels)\n",
    "\n",
    "        for i in range(k, 100):\n",
    "            diff = abs(fc_labels[str(i)] - mean)\n",
    "            if diff < kSimilarLabels[k-1][1]:\n",
    "                kSimilarLabels.pop()\n",
    "                kSimilarLabels.append((i, diff.item()))\n",
    "                kSimilarLabels.sort(key = lambda x:x[1])\n",
    "        print(kSimilarLabels)  \n",
    "\n",
    "#getKMatchingLabels(imread(\"13.png\"), 10, \"1\")\n",
    "getKMatchingLabels(dataset[0][0], 10, \"4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "735cae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../CSE515-Project\"\n",
    "\n",
    "def getResnet50Label(id):\n",
    "#resize image\n",
    "    imOpen = np.asarray(dataset[id][0])\n",
    "\n",
    "    resizedImg = resize(imOpen, (224,224))\n",
    "    #print(\"Shape:\" + str(resizedImg.shape))\n",
    "    matplotlib.image.imsave('resized.jpg', resizedImg)\n",
    "    resizedImgNp = imread(path + '/resized.jpg')\n",
    "\n",
    "    npDataset = torch.tensor([np.transpose(resizedImgNp)])\n",
    "    #print(\"Shape:\" + str(npDataset.shape))\n",
    "\n",
    "    rn_model =  torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    rn_model.eval()\n",
    "    rn_model(npDataset.float())\n",
    "    print(rn_model)\n",
    "\n",
    "#getResnet50Label(id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
